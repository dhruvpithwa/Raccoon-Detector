{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RaccoonDetector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRIj10jNhqH1",
        "outputId": "4a17da33-0e86-4cb7-8c18-51331613c855",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Our YOLOv3 implementation calls for this Keras version\n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.4\n",
            "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.6 (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r788kvmKuD5O"
      },
      "source": [
        "# use TF 1.x\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMI-zNrrhmuG",
        "outputId": "4d590634-d886-4e51-f1ff-07a2d2acfcf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Verify our version is correct\n",
        "!python -c 'import keras; print(keras.__version__)'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lweWDcTyVeLs",
        "outputId": "7ecd5bd8-1aad-4459-9a37-3e0148ee2b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Next, we'll grab all the code from our repository of interest \n",
        "!git clone https://github.com/roboflow-ai/keras-yolo3.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-yolo3'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Total 169 (delta 0), reused 0 (delta 0), pack-reused 169\u001b[K\n",
            "Receiving objects: 100% (169/169), 172.74 KiB | 6.91 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyPfLjFBbOAw",
        "outputId": "7a819422-1dca-4bfb-e19f-e2c1427f4b40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# here's what we cloned (also, see \"Files\" in the left-hand Colab pane)\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mkeras-yolo3\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adwdKfxBVlom",
        "outputId": "142a61df-a70a-4491-c399-0d3154a0f339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# change directory to the repo we cloned\n",
        "%cd keras-yolo3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6DNWhOEbGB6",
        "outputId": "933257b9-4533-40de-ce5e-9e18e6880703",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# show the contents of our repo\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coco_annotation.py  LICENSE              Tutorial.ipynb     yolov3-tiny.cfg\n",
            "convert.py          \u001b[0m\u001b[01;34mmodel_data\u001b[0m/          voc_annotation.py  yolo_video.py\n",
            "darknet53.cfg       README.md            \u001b[01;34myolo3\u001b[0m/\n",
            "\u001b[01;34mfont\u001b[0m/               train_bottleneck.py  yolo.py\n",
            "kmeans.py           train.py             yolov3.cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nclkjonbT25",
        "outputId": "e2344a56-1868-42eb-9cc3-38beec736678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Paste Roboflow code from snippet here from above to here! eg !curl -L https://app.roboflow.ai/ds/eOSXbt7KWu?key=YOURKEY | jar -x\n",
        "!curl -L raccoon-public-dataset-link-roboflow > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   892  100   892    0     0   1186      0 --:--:-- --:--:-- --:--:--  1187\n",
            "100 5843k  100 5843k    0     0  5024k      0  0:00:01  0:00:01 --:--:-- 27.7M\n",
            "Archive:  roboflow.zip\n",
            " extracting: export/raccoon-148_jpg.rf.10e85a4558497606e6a129b36207f3e3.jpg  \n",
            " extracting: export/raccoon-92_jpg.rf.133d7820d01e7c6ed215ae7d7e01024a.jpg  \n",
            " extracting: export/raccoon-169_jpg.rf.09a73c6089cf8e4915cc86dab2fd3649.jpg  \n",
            " extracting: export/raccoon-72_jpg.rf.09d8c9ddaa3ced1775fcd27de1418ff9.jpg  \n",
            " extracting: export/raccoon-74_jpg.rf.066959b69f0c6562591e814f4341f4cd.jpg  \n",
            " extracting: export/raccoon-113_jpg.rf.116816776f04bc77daf644271ebbea6e.jpg  \n",
            " extracting: export/raccoon-29_jpg.rf.0567862dbebd6fffcaba892ab37b2ddd.jpg  \n",
            " extracting: export/raccoon-97_jpg.rf.0ba0682a10ff3ebc75cf69cc4dead5d6.jpg  \n",
            " extracting: export/raccoon-193_jpg.rf.03d581ee72066e68248b554e638b6996.jpg  \n",
            " extracting: export/raccoon-138_jpg.rf.15fb36757722f5a3de5a182eea4ddd1d.jpg  \n",
            " extracting: export/raccoon-160_jpg.rf.14d9cf8c2ee0c1503526e9ee97ef04e6.jpg  \n",
            " extracting: export/raccoon-131_jpg.rf.1847a5d545db92e180fa19e70c8494e3.jpg  \n",
            " extracting: export/raccoon-188_jpg.rf.15559b07bc3a0d05391951c53f1955f0.jpg  \n",
            " extracting: export/raccoon-197_jpg.rf.1618acd413190fefe1ba8db64b8f1611.jpg  \n",
            " extracting: export/raccoon-191_jpg.rf.1d78cbf98a37ddcd43e0d32d68fabf41.jpg  \n",
            " extracting: export/raccoon-173_jpg.rf.1e2fb3444df4c9fd688e8b0ca0366123.jpg  \n",
            " extracting: export/raccoon-112_jpg.rf.1b6a920ea5e2d9085eea8c70f67aee3f.jpg  \n",
            " extracting: export/raccoon-45_jpg.rf.1480da793fa93f91fe244fc567aed67c.jpg  \n",
            " extracting: export/raccoon-143_jpg.rf.18ff45882e381639888076ae0e396bc2.jpg  \n",
            " extracting: export/raccoon-83_jpg.rf.0e0db31713d7357475e641139088dac4.jpg  \n",
            " extracting: export/raccoon-147_jpg.rf.23be863ec517863aa3e7e26dd652b66f.jpg  \n",
            " extracting: export/raccoon-67_jpg.rf.246be1b8226d287a8a7fb35692c1a77d.jpg  \n",
            " extracting: export/raccoon-71_jpg.rf.240f0810d81630e8ebc3934f9e0c560c.jpg  \n",
            " extracting: export/raccoon-20_jpg.rf.244261846b4168eb24f37b25255e2a16.jpg  \n",
            " extracting: export/raccoon-178_jpg.rf.2142d32063387bfc178fca79eba27908.jpg  \n",
            " extracting: export/raccoon-159_jpg.rf.2c1ee26f22884dcd54cd7cb388027625.jpg  \n",
            " extracting: export/raccoon-5_jpg.rf.28fdf4e1d910678ae5f41fce0dd03dc7.jpg  \n",
            " extracting: export/raccoon-25_jpg.rf.25af8b272e0821ec0c4668826de46b57.jpg  \n",
            " extracting: export/raccoon-181_jpg.rf.268688ca628bb4787fe7a6200b6739cc.jpg  \n",
            " extracting: export/raccoon-194_jpg.rf.278aae5524a89af15ef133e713a8fd15.jpg  \n",
            " extracting: export/raccoon-90_jpg.rf.352c80a3dfabd3690a8b9c3141025280.jpg  \n",
            " extracting: export/raccoon-68_jpg.rf.2e710308e7e67745aa4c2518570efb44.jpg  \n",
            " extracting: export/raccoon-4_jpg.rf.2f18e7988aed4775867392aa38ccdb35.jpg  \n",
            " extracting: export/raccoon-109_jpg.rf.30bfd64dcc48e0a698628d597a77c538.jpg  \n",
            " extracting: export/raccoon-180_jpg.rf.386d6a60d32a697211ec1effbf9b0d47.jpg  \n",
            " extracting: export/raccoon-21_jpg.rf.3683dd66af9f007fa8340ad62a57bcfd.jpg  \n",
            " extracting: export/raccoon-132_jpg.rf.372e4ab6a9f28584576a7f3356e2543f.jpg  \n",
            " extracting: export/raccoon-2_jpg.rf.394e4e2da5f4eb736a6ef2328602d64c.jpg  \n",
            " extracting: export/raccoon-18_jpg.rf.37f582b9c3740f41b9b001d6231e9624.jpg  \n",
            " extracting: export/raccoon-62_jpg.rf.3d3012f438c37c1abb71842cd7bb22db.jpg  \n",
            " extracting: export/raccoon-98_jpg.rf.3e84bb66ca7d8c90b24918510a99aba1.jpg  \n",
            " extracting: export/raccoon-95_jpg.rf.3c88c796d81ddbd0a558edb023a29630.jpg  \n",
            " extracting: export/raccoon-130_jpg.rf.3b5f11f6dc182d577296f1936de10dd6.jpg  \n",
            " extracting: export/raccoon-81_jpg.rf.3ab8029c18a7e09462a9992bb72c6a26.jpg  \n",
            " extracting: export/raccoon-153_jpg.rf.416e2ffa4b48443da2cda29beae3a262.jpg  \n",
            " extracting: export/raccoon-63_jpg.rf.40ab9d24c7da1e9e9fb596f478516b61.jpg  \n",
            " extracting: export/raccoon-11_jpg.rf.42a1a7abcfc445e318a674904b043722.jpg  \n",
            " extracting: export/raccoon-150_jpg.rf.46e71116a4737144dc56f609f7297f14.jpg  \n",
            " extracting: export/raccoon-189_jpg.rf.43419901d98eee0056c28df38e6513d7.jpg  \n",
            " extracting: export/raccoon-102_jpg.rf.45e0bc55ec8c5ed234a7032622fa4343.jpg  \n",
            " extracting: export/raccoon-171_jpg.rf.477b2ddd78334618e0c6cdc38d4332eb.jpg  \n",
            " extracting: export/raccoon-58_jpg.rf.4888dd77d2a83089f413f13d95159063.jpg  \n",
            " extracting: export/raccoon-91_jpg.rf.456ec1187ce1f6cc26efa9efd4812f23.jpg  \n",
            " extracting: export/raccoon-76_jpg.rf.48ea30b685740264da032302faa1bc84.jpg  \n",
            " extracting: export/raccoon-139_jpg.rf.4974e71827b7315599427fd08f26d4ab.jpg  \n",
            " extracting: export/raccoon-123_jpg.rf.4c33da4a15192e4edbeabeb01c3bc79a.jpg  \n",
            " extracting: export/raccoon-183_jpg.rf.4db3a27af872e3171b8c20e7067341b6.jpg  \n",
            " extracting: export/raccoon-17_jpg.rf.4a4a70dd81df00203f1903fd6bb009ba.jpg  \n",
            " extracting: export/raccoon-84_jpg.rf.4a7baffb45287ee96863f030bb0a76b8.jpg  \n",
            " extracting: export/raccoon-110_jpg.rf.506fcfbc8dd4175b123fd5064b3471e6.jpg  \n",
            " extracting: export/raccoon-100_jpg.rf.52f39daea32ee9dc7265a6c591c37313.jpg  \n",
            " extracting: export/raccoon-195_jpg.rf.51ec933cf17263f4d8b5858eb8206361.jpg  \n",
            " extracting: export/raccoon-187_jpg.rf.4f618a6eff7dcd1ec5eaa0c41e00f37f.jpg  \n",
            " extracting: export/raccoon-165_jpg.rf.51dfb3c8130c8273c2c103834e4889da.jpg  \n",
            " extracting: export/raccoon-115_jpg.rf.5205b38e218dd901fd21c135975b9fa9.jpg  \n",
            " extracting: export/raccoon-38_jpg.rf.5675fe2d015a746eaeece74213190ac9.jpg  \n",
            " extracting: export/raccoon-22_jpg.rf.56c95e99e258acd95d54cca330058adf.jpg  \n",
            " extracting: export/raccoon-168_jpg.rf.5699ce9cc71dc0387026d1b16626bf84.jpg  \n",
            " extracting: export/raccoon-66_jpg.rf.55771c3cc5e75cef82e0da3a43f0197a.jpg  \n",
            " extracting: export/raccoon-23_jpg.rf.5ab2f34cf8ba061c08a6f247a483fcd3.jpg  \n",
            " extracting: export/raccoon-8_jpg.rf.56f046e0ec9164c18dcb786a5d8b56a9.jpg  \n",
            " extracting: export/raccoon-134_jpg.rf.5a43c362ed61b4e6c0f82b6cc29e802e.jpg  \n",
            " extracting: export/raccoon-16_jpg.rf.58a72de057cdbb407dbcf66244bc5934.jpg  \n",
            " extracting: export/raccoon-15_jpg.rf.5bf2e3dc3100e256e042d94a1d88f515.jpg  \n",
            " extracting: export/raccoon-137_jpg.rf.5a2530312b2ba5d5852129a5b9fae725.jpg  \n",
            " extracting: export/raccoon-60_jpg.rf.585ecfc2b55fa5b8f4f183d6d077292a.jpg  \n",
            " extracting: export/raccoon-99_jpg.rf.5e8a99eb16568172b27c208dd0a3a2ef.jpg  \n",
            " extracting: export/raccoon-170_jpg.rf.5d11723aa88f09746fa20bfa0f7d6be9.jpg  \n",
            " extracting: export/raccoon-79_jpg.rf.5df522491245bf4a8f3d6fbc12461060.jpg  \n",
            " extracting: export/raccoon-154_jpg.rf.623df806d7fe78c27f72327370543040.jpg  \n",
            " extracting: export/raccoon-144_jpg.rf.60dba86064a0b8b431d0624b79583115.jpg  \n",
            " extracting: export/raccoon-156_jpg.rf.5c67b0af8774e1a803c69dfd57ed3bf9.jpg  \n",
            " extracting: export/raccoon-179_jpg.rf.60de8d933754866816a181e69396559d.jpg  \n",
            " extracting: export/raccoon-172_jpg.rf.6001c700d7eb01da8ef7d95f12194dd8.jpg  \n",
            " extracting: export/raccoon-124_jpg.rf.5a97e2ade3d1e8bbcf329750a9ccd6ea.jpg  \n",
            " extracting: export/raccoon-43_jpg.rf.5cb21177b5e0c41d0f1ca42010d82b42.jpg  \n",
            " extracting: export/raccoon-105_jpg.rf.635f1284ef2d378438456e10e119f1e2.jpg  \n",
            " extracting: export/raccoon-186_jpg.rf.625d95025f84abf9856080b2faa5c383.jpg  \n",
            " extracting: export/raccoon-86_jpg.rf.68467edd5d4bd779424dbb9cfc2f08ec.jpg  \n",
            " extracting: export/raccoon-47_jpg.rf.672d0251a0441c2e6afd0499aaed4c3a.jpg  \n",
            " extracting: export/raccoon-162_jpg.rf.698e8febf42bc8d0e5c144c4989ac7b7.jpg  \n",
            " extracting: export/raccoon-184_jpg.rf.69dc52b620d9bca66d593079b10622a9.jpg  \n",
            " extracting: export/raccoon-59_jpg.rf.6584b902e32ec3936a7fd3997ab72cbc.jpg  \n",
            " extracting: export/raccoon-42_jpg.rf.6c0893bad5f7066d7ab67e9f6e930148.jpg  \n",
            " extracting: export/raccoon-70_jpg.rf.6d4fd75d2f2c02ea0cdee36936024c17.jpg  \n",
            " extracting: export/raccoon-10_jpg.rf.6aafaf3e5397ca2620657903fe4c7eba.jpg  \n",
            " extracting: export/raccoon-157_jpg.rf.6facfcd86fac6b9ec043e796fbbd1a43.jpg  \n",
            " extracting: export/raccoon-6_jpg.rf.744d0921d61b139fd0d5c0e74ca11740.jpg  \n",
            " extracting: export/raccoon-69_jpg.rf.7409be2f6fcdb4202877b7cee84d0cfd.jpg  \n",
            " extracting: export/raccoon-13_jpg.rf.7439e7ac8c5d2bf7c06d6d34054d42b7.jpg  \n",
            " extracting: export/raccoon-196_jpg.rf.7675561c8f73dd7dbf67d7d059d9d1c1.jpg  \n",
            " extracting: export/raccoon-34_jpg.rf.726b010640d29591f1ed56d99456a7e5.jpg  \n",
            " extracting: export/raccoon-118_jpg.rf.79cd0054dbdfe9b2422503a1ca696221.jpg  \n",
            " extracting: export/raccoon-19_jpg.rf.7267af95f8224c24ae68628b326b9a93.jpg  \n",
            " extracting: export/raccoon-53_jpg.rf.72cbe940898e4f2511fc77ec9a070072.jpg  \n",
            " extracting: export/raccoon-163_jpg.rf.7df6926686bffd066db7ffb5777855ee.jpg  \n",
            " extracting: export/raccoon-77_jpg.rf.8102b983498de2cfc317b57293dc19b9.jpg  \n",
            " extracting: export/raccoon-121_jpg.rf.805b9c0c518bfe5c8926fb0350534228.jpg  \n",
            " extracting: export/raccoon-27_jpg.rf.826ff28a701a55c79927c052d879bdbf.jpg  \n",
            " extracting: export/raccoon-127_jpg.rf.812ca10aa7e715abf1149adba9e32597.jpg  \n",
            " extracting: export/raccoon-1_jpg.rf.86bf2eb4366711ee98b3eff5328302e5.jpg  \n",
            " extracting: export/raccoon-73_jpg.rf.8757fde35aa40b69caa4014d0355b272.jpg  \n",
            " extracting: export/raccoon-26_jpg.rf.81e42bb69c8c480289dc656c482e14b0.jpg  \n",
            " extracting: export/raccoon-82_jpg.rf.843d438f343388e94dcfe027978edac6.jpg  \n",
            " extracting: export/raccoon-117_jpg.rf.84694b89935d96d720922b95709a5e5e.jpg  \n",
            " extracting: export/raccoon-182_jpg.rf.9a25863af008098d76baf7015cff4bbb.jpg  \n",
            " extracting: export/raccoon-89_jpg.rf.9d1b4109472683bb28668c160e80a8f4.jpg  \n",
            " extracting: export/raccoon-166_jpg.rf.954cd8bb97ed9638a630b8861e9b17ed.jpg  \n",
            " extracting: export/raccoon-119_jpg.rf.9e3522b241e9b90cf5ed6f36d79669ea.jpg  \n",
            " extracting: export/raccoon-146_jpg.rf.923376f3460dcc36a74909d2620e5c1e.jpg  \n",
            " extracting: export/raccoon-167_jpg.rf.951f708822d25cf6526d670611c6f943.jpg  \n",
            " extracting: export/raccoon-122_jpg.rf.a07845b7b3fe4ca90ac917942f891a08.jpg  \n",
            " extracting: export/raccoon-126_jpg.rf.9fb10a508fd7d2c35b56727d0526c99e.jpg  \n",
            " extracting: export/raccoon-114_jpg.rf.a423d0e91659c2de182a34d59281af27.jpg  \n",
            " extracting: export/raccoon-51_jpg.rf.8bf83dabfcd0abb0baa44d6647d50629.jpg  \n",
            " extracting: export/raccoon-75_jpg.rf.a516d1392d6c6859b50884b2128d3f21.jpg  \n",
            " extracting: export/raccoon-50_jpg.rf.9f6f2e4a156b334f2b88e1254a0b7395.jpg  \n",
            " extracting: export/raccoon-129_jpg.rf.aa19c70ae1c1c0199a8681c9e9f98753.jpg  \n",
            " extracting: export/raccoon-155_jpg.rf.a81e6eb3ca44a3896b0c7a984c395872.jpg  \n",
            " extracting: export/raccoon-140_jpg.rf.b305669324d984cefd0e302903dfbb61.jpg  \n",
            " extracting: export/raccoon-37_jpg.rf.b3ed752a15d92357d867f2fd686979d7.jpg  \n",
            " extracting: export/raccoon-33_jpg.rf.ae8420e9765b852c7010db558c38f50b.jpg  \n",
            " extracting: export/raccoon-175_jpg.rf.b35926e3afc4409406565c0b29e463ee.jpg  \n",
            " extracting: export/raccoon-9_jpg.rf.bc05f3ccbc3e5461d54784033ea94f85.jpg  \n",
            " extracting: export/raccoon-31_jpg.rf.b6cbaf67fc83b3abcac857bd719d5249.jpg  \n",
            " extracting: export/raccoon-164_jpg.rf.b69dc2b7fb6a02c6d22f658238444dfc.jpg  \n",
            " extracting: export/raccoon-198_jpg.rf.bc433633240733231697f61567a1ba12.jpg  \n",
            " extracting: export/raccoon-107_jpg.rf.bcebd400f5f02555d1637bac7c1c5f1e.jpg  \n",
            " extracting: export/raccoon-185_jpg.rf.bcee2ca430fb3a96dc514b1992e47c0e.jpg  \n",
            " extracting: export/raccoon-80_jpg.rf.b575161bdf772884fe088c5053279c51.jpg  \n",
            " extracting: export/raccoon-152_jpg.rf.c21589c11e3949ed20f02bc867e491a5.jpg  \n",
            " extracting: export/raccoon-64_jpg.rf.bc00e2ddcc336d5005c9d94335274166.jpg  \n",
            " extracting: export/raccoon-161_jpg.rf.b442cc51e51c950473ec4f7623ce2b07.jpg  \n",
            " extracting: export/raccoon-61_jpg.rf.c6213e0b4190e43f3d31c75be9e72918.jpg  \n",
            " extracting: export/raccoon-94_jpg.rf.c3a646ebb73c5645c2196cad78567fb7.jpg  \n",
            " extracting: export/raccoon-78_jpg.rf.cb2b49d5f1967aa5469a519d8e13ac9f.jpg  \n",
            " extracting: export/raccoon-192_jpg.rf.ca51aeee5c3377d3552b77250546a780.jpg  \n",
            " extracting: export/raccoon-35_jpg.rf.c62e88f203c511ca72c94e3b675b821f.jpg  \n",
            " extracting: export/raccoon-55_jpg.rf.cae530a32dfcd3f589fc0d196d4b7c0a.jpg  \n",
            " extracting: export/raccoon-135_jpg.rf.cbba4e3d1c699114824249e5375f47aa.jpg  \n",
            " extracting: export/raccoon-36_jpg.rf.d0160b58eabb77c9da48526b1075516a.jpg  \n",
            " extracting: export/raccoon-48_jpg.rf.c8630eddd2247c914cd5761cde8768e1.jpg  \n",
            " extracting: export/raccoon-44_jpg.rf.cc54a80489215e4d20119067414e7283.jpg  \n",
            " extracting: export/raccoon-88_jpg.rf.d12326b0a21d4195397756fcb2601ea8.jpg  \n",
            " extracting: export/raccoon-54_jpg.rf.d21192d347b1bd3595809549e9066f18.jpg  \n",
            " extracting: export/raccoon-128_jpg.rf.d02d947edecdd0a4281bce7917aa0ab9.jpg  \n",
            " extracting: export/raccoon-200_jpg.rf.d3a7d9a0902b424d082689db76cf99f4.jpg  \n",
            " extracting: export/raccoon-30_jpg.rf.d21598f34e1977d0fb06029f6250c6ab.jpg  \n",
            " extracting: export/raccoon-174_jpg.rf.e311c9dc3467d64ea7553dc3d97741cd.jpg  \n",
            " extracting: export/raccoon-108_jpg.rf.deccf8708714c2088ea63055532f816e.jpg  \n",
            " extracting: export/raccoon-3_jpg.rf.d69de8d188e9ce4560447c09e2b2895f.jpg  \n",
            " extracting: export/raccoon-93_jpg.rf.d70f3da0950d00bcd9c9aa23ca56327e.jpg  \n",
            " extracting: export/raccoon-32_jpg.rf.d7b4232bc660c86e4d019040fd1e38c6.jpg  \n",
            " extracting: export/raccoon-41_jpg.rf.e35cfc84d0f7028c4cae77fe88f49ac5.jpg  \n",
            " extracting: export/raccoon-136_jpg.rf.e3f0d8942735360a0c7db8fcba8239bc.jpg  \n",
            " extracting: export/raccoon-7_jpg.rf.dce2f8be9b79db5e6597ffc7ae6f4c86.jpg  \n",
            " extracting: export/raccoon-177_jpg.rf.e4eb1c989815ce10877db5afa0ebd240.jpg  \n",
            " extracting: export/raccoon-149_jpg.rf.e46a9a8f9e7260ff48e86815fc0e0dda.jpg  \n",
            " extracting: export/raccoon-46_jpg.rf.e7a366a949d2e6d7fbff5ab4069d03ce.jpg  \n",
            " extracting: export/raccoon-96_jpg.rf.e979b7f400aeb27038a19702c0dea238.jpg  \n",
            " extracting: export/raccoon-106_jpg.rf.e9025ab979fda072ad42f9b7c8d14657.jpg  \n",
            " extracting: export/raccoon-133_jpg.rf.d9bbf773940bf3e55152221c5bf47c25.jpg  \n",
            " extracting: export/raccoon-151_jpg.rf.eaf20f212c6d8832667eb12b45b9780e.jpg  \n",
            " extracting: export/raccoon-24_jpg.rf.e5da2610dedc18a62487b20f2fdf536f.jpg  \n",
            " extracting: export/raccoon-12_jpg.rf.eb97e80628970878966b353cc1cc9aea.jpg  \n",
            " extracting: export/raccoon-85_jpg.rf.f1477931a2b7277e01033bee3f7da11b.jpg  \n",
            " extracting: export/raccoon-125_jpg.rf.ed5a8565bfa2f0fdcbc5be2e4b468a2b.jpg  \n",
            " extracting: export/raccoon-142_jpg.rf.ece6d87d78f0061c4707925f753d608a.jpg  \n",
            " extracting: export/raccoon-158_jpg.rf.f62f5b90800dbcf624fd0a51b789d8aa.jpg  \n",
            " extracting: export/raccoon-141_jpg.rf.e377c966517aa207bb4c5273fecfbacf.jpg  \n",
            " extracting: export/raccoon-104_jpg.rf.ed0b04834a4c1d3d7e304f429ecca69f.jpg  \n",
            " extracting: export/raccoon-111_jpg.rf.f74582eaf6c958c8c96e19d6d557cb45.jpg  \n",
            " extracting: export/raccoon-101_jpg.rf.f892f114fd9fa83f9a5a503a0f473a0e.jpg  \n",
            " extracting: export/raccoon-87_jpg.rf.f2c7b747fc717134c75aa3e97460ac19.jpg  \n",
            " extracting: export/raccoon-199_jpg.rf.f94c56b7b4a846f37c5e38e95c1d93c3.jpg  \n",
            " extracting: export/raccoon-176_jpg.rf.fb8dfc82e718293519ce4f00ed9e3f13.jpg  \n",
            " extracting: export/raccoon-14_jpg.rf.fc138a4cc4a4cec6a8193a523005b6fd.jpg  \n",
            " extracting: export/raccoon-39_jpg.rf.fd9ae13c9c529196f7fb2a291cb14308.jpg  \n",
            " extracting: export/raccoon-145_jpg.rf.fcc58ad45099f01287b35962d8d075c8.jpg  \n",
            " extracting: export/raccoon-49_jpg.rf.fc86a92c2a808a257d529e372f2a123e.jpg  \n",
            " extracting: export/raccoon-190_jpg.rf.fe4cbeabd2bb36162b7de124c03ad2f9.jpg  \n",
            " extracting: export/raccoon-28_jpg.rf.fe5aedd8ec0f8606941c940bc329eb0e.jpg  \n",
            " extracting: export/raccoon-40_jpg.rf.ff7d6e71001ba529c099bb856103e654.jpg  \n",
            " extracting: export/raccoon-56_jpg.rf.fe3e6632931a0ab31a0a303bf0e4b032.jpg  \n",
            " extracting: export/raccoon-57_jpg.rf.fefb3f212af9dfeb38411ee2e855ecea.jpg  \n",
            " extracting: export/raccoon-103_jpg.rf.fff35dffbd15d190078b7bba13597813.jpg  \n",
            " extracting: export/_annotations.txt  \n",
            " extracting: export/_classes.txt     \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: README.dataset.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izGzSaeJzqAl",
        "outputId": "a4973469-3267-4103-e1a2-806ebff067a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coco_annotation.py  kmeans.py           README.roboflow.txt  \u001b[0m\u001b[01;34myolo3\u001b[0m/\n",
            "convert.py          LICENSE             train_bottleneck.py  yolo.py\n",
            "darknet53.cfg       \u001b[01;34mmodel_data\u001b[0m/         train.py             yolov3.cfg\n",
            "\u001b[01;34mexport\u001b[0m/             README.dataset.txt  Tutorial.ipynb       yolov3-tiny.cfg\n",
            "\u001b[01;34mfont\u001b[0m/               README.md           voc_annotation.py    yolo_video.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1PagPopmUIG",
        "outputId": "b1dd06be-8ef1-4496-9503-073f857d8698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# change directory into our export folder from Roboflow\n",
        "%cd export"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3/export\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ372c7gWN_p",
        "outputId": "ab59ee16-9fd3-421e-b910-84ac5cc21e8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# show what came with the Roboflow export\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_annotations.txt\n",
            "_classes.txt\n",
            "raccoon-100_jpg.rf.52f39daea32ee9dc7265a6c591c37313.jpg\n",
            "raccoon-101_jpg.rf.f892f114fd9fa83f9a5a503a0f473a0e.jpg\n",
            "raccoon-102_jpg.rf.45e0bc55ec8c5ed234a7032622fa4343.jpg\n",
            "raccoon-103_jpg.rf.fff35dffbd15d190078b7bba13597813.jpg\n",
            "raccoon-104_jpg.rf.ed0b04834a4c1d3d7e304f429ecca69f.jpg\n",
            "raccoon-105_jpg.rf.635f1284ef2d378438456e10e119f1e2.jpg\n",
            "raccoon-106_jpg.rf.e9025ab979fda072ad42f9b7c8d14657.jpg\n",
            "raccoon-107_jpg.rf.bcebd400f5f02555d1637bac7c1c5f1e.jpg\n",
            "raccoon-108_jpg.rf.deccf8708714c2088ea63055532f816e.jpg\n",
            "raccoon-109_jpg.rf.30bfd64dcc48e0a698628d597a77c538.jpg\n",
            "raccoon-10_jpg.rf.6aafaf3e5397ca2620657903fe4c7eba.jpg\n",
            "raccoon-110_jpg.rf.506fcfbc8dd4175b123fd5064b3471e6.jpg\n",
            "raccoon-111_jpg.rf.f74582eaf6c958c8c96e19d6d557cb45.jpg\n",
            "raccoon-112_jpg.rf.1b6a920ea5e2d9085eea8c70f67aee3f.jpg\n",
            "raccoon-113_jpg.rf.116816776f04bc77daf644271ebbea6e.jpg\n",
            "raccoon-114_jpg.rf.a423d0e91659c2de182a34d59281af27.jpg\n",
            "raccoon-115_jpg.rf.5205b38e218dd901fd21c135975b9fa9.jpg\n",
            "raccoon-117_jpg.rf.84694b89935d96d720922b95709a5e5e.jpg\n",
            "raccoon-118_jpg.rf.79cd0054dbdfe9b2422503a1ca696221.jpg\n",
            "raccoon-119_jpg.rf.9e3522b241e9b90cf5ed6f36d79669ea.jpg\n",
            "raccoon-11_jpg.rf.42a1a7abcfc445e318a674904b043722.jpg\n",
            "raccoon-121_jpg.rf.805b9c0c518bfe5c8926fb0350534228.jpg\n",
            "raccoon-122_jpg.rf.a07845b7b3fe4ca90ac917942f891a08.jpg\n",
            "raccoon-123_jpg.rf.4c33da4a15192e4edbeabeb01c3bc79a.jpg\n",
            "raccoon-124_jpg.rf.5a97e2ade3d1e8bbcf329750a9ccd6ea.jpg\n",
            "raccoon-125_jpg.rf.ed5a8565bfa2f0fdcbc5be2e4b468a2b.jpg\n",
            "raccoon-126_jpg.rf.9fb10a508fd7d2c35b56727d0526c99e.jpg\n",
            "raccoon-127_jpg.rf.812ca10aa7e715abf1149adba9e32597.jpg\n",
            "raccoon-128_jpg.rf.d02d947edecdd0a4281bce7917aa0ab9.jpg\n",
            "raccoon-129_jpg.rf.aa19c70ae1c1c0199a8681c9e9f98753.jpg\n",
            "raccoon-12_jpg.rf.eb97e80628970878966b353cc1cc9aea.jpg\n",
            "raccoon-130_jpg.rf.3b5f11f6dc182d577296f1936de10dd6.jpg\n",
            "raccoon-131_jpg.rf.1847a5d545db92e180fa19e70c8494e3.jpg\n",
            "raccoon-132_jpg.rf.372e4ab6a9f28584576a7f3356e2543f.jpg\n",
            "raccoon-133_jpg.rf.d9bbf773940bf3e55152221c5bf47c25.jpg\n",
            "raccoon-134_jpg.rf.5a43c362ed61b4e6c0f82b6cc29e802e.jpg\n",
            "raccoon-135_jpg.rf.cbba4e3d1c699114824249e5375f47aa.jpg\n",
            "raccoon-136_jpg.rf.e3f0d8942735360a0c7db8fcba8239bc.jpg\n",
            "raccoon-137_jpg.rf.5a2530312b2ba5d5852129a5b9fae725.jpg\n",
            "raccoon-138_jpg.rf.15fb36757722f5a3de5a182eea4ddd1d.jpg\n",
            "raccoon-139_jpg.rf.4974e71827b7315599427fd08f26d4ab.jpg\n",
            "raccoon-13_jpg.rf.7439e7ac8c5d2bf7c06d6d34054d42b7.jpg\n",
            "raccoon-140_jpg.rf.b305669324d984cefd0e302903dfbb61.jpg\n",
            "raccoon-141_jpg.rf.e377c966517aa207bb4c5273fecfbacf.jpg\n",
            "raccoon-142_jpg.rf.ece6d87d78f0061c4707925f753d608a.jpg\n",
            "raccoon-143_jpg.rf.18ff45882e381639888076ae0e396bc2.jpg\n",
            "raccoon-144_jpg.rf.60dba86064a0b8b431d0624b79583115.jpg\n",
            "raccoon-145_jpg.rf.fcc58ad45099f01287b35962d8d075c8.jpg\n",
            "raccoon-146_jpg.rf.923376f3460dcc36a74909d2620e5c1e.jpg\n",
            "raccoon-147_jpg.rf.23be863ec517863aa3e7e26dd652b66f.jpg\n",
            "raccoon-148_jpg.rf.10e85a4558497606e6a129b36207f3e3.jpg\n",
            "raccoon-149_jpg.rf.e46a9a8f9e7260ff48e86815fc0e0dda.jpg\n",
            "raccoon-14_jpg.rf.fc138a4cc4a4cec6a8193a523005b6fd.jpg\n",
            "raccoon-150_jpg.rf.46e71116a4737144dc56f609f7297f14.jpg\n",
            "raccoon-151_jpg.rf.eaf20f212c6d8832667eb12b45b9780e.jpg\n",
            "raccoon-152_jpg.rf.c21589c11e3949ed20f02bc867e491a5.jpg\n",
            "raccoon-153_jpg.rf.416e2ffa4b48443da2cda29beae3a262.jpg\n",
            "raccoon-154_jpg.rf.623df806d7fe78c27f72327370543040.jpg\n",
            "raccoon-155_jpg.rf.a81e6eb3ca44a3896b0c7a984c395872.jpg\n",
            "raccoon-156_jpg.rf.5c67b0af8774e1a803c69dfd57ed3bf9.jpg\n",
            "raccoon-157_jpg.rf.6facfcd86fac6b9ec043e796fbbd1a43.jpg\n",
            "raccoon-158_jpg.rf.f62f5b90800dbcf624fd0a51b789d8aa.jpg\n",
            "raccoon-159_jpg.rf.2c1ee26f22884dcd54cd7cb388027625.jpg\n",
            "raccoon-15_jpg.rf.5bf2e3dc3100e256e042d94a1d88f515.jpg\n",
            "raccoon-160_jpg.rf.14d9cf8c2ee0c1503526e9ee97ef04e6.jpg\n",
            "raccoon-161_jpg.rf.b442cc51e51c950473ec4f7623ce2b07.jpg\n",
            "raccoon-162_jpg.rf.698e8febf42bc8d0e5c144c4989ac7b7.jpg\n",
            "raccoon-163_jpg.rf.7df6926686bffd066db7ffb5777855ee.jpg\n",
            "raccoon-164_jpg.rf.b69dc2b7fb6a02c6d22f658238444dfc.jpg\n",
            "raccoon-165_jpg.rf.51dfb3c8130c8273c2c103834e4889da.jpg\n",
            "raccoon-166_jpg.rf.954cd8bb97ed9638a630b8861e9b17ed.jpg\n",
            "raccoon-167_jpg.rf.951f708822d25cf6526d670611c6f943.jpg\n",
            "raccoon-168_jpg.rf.5699ce9cc71dc0387026d1b16626bf84.jpg\n",
            "raccoon-169_jpg.rf.09a73c6089cf8e4915cc86dab2fd3649.jpg\n",
            "raccoon-16_jpg.rf.58a72de057cdbb407dbcf66244bc5934.jpg\n",
            "raccoon-170_jpg.rf.5d11723aa88f09746fa20bfa0f7d6be9.jpg\n",
            "raccoon-171_jpg.rf.477b2ddd78334618e0c6cdc38d4332eb.jpg\n",
            "raccoon-172_jpg.rf.6001c700d7eb01da8ef7d95f12194dd8.jpg\n",
            "raccoon-173_jpg.rf.1e2fb3444df4c9fd688e8b0ca0366123.jpg\n",
            "raccoon-174_jpg.rf.e311c9dc3467d64ea7553dc3d97741cd.jpg\n",
            "raccoon-175_jpg.rf.b35926e3afc4409406565c0b29e463ee.jpg\n",
            "raccoon-176_jpg.rf.fb8dfc82e718293519ce4f00ed9e3f13.jpg\n",
            "raccoon-177_jpg.rf.e4eb1c989815ce10877db5afa0ebd240.jpg\n",
            "raccoon-178_jpg.rf.2142d32063387bfc178fca79eba27908.jpg\n",
            "raccoon-179_jpg.rf.60de8d933754866816a181e69396559d.jpg\n",
            "raccoon-17_jpg.rf.4a4a70dd81df00203f1903fd6bb009ba.jpg\n",
            "raccoon-180_jpg.rf.386d6a60d32a697211ec1effbf9b0d47.jpg\n",
            "raccoon-181_jpg.rf.268688ca628bb4787fe7a6200b6739cc.jpg\n",
            "raccoon-182_jpg.rf.9a25863af008098d76baf7015cff4bbb.jpg\n",
            "raccoon-183_jpg.rf.4db3a27af872e3171b8c20e7067341b6.jpg\n",
            "raccoon-184_jpg.rf.69dc52b620d9bca66d593079b10622a9.jpg\n",
            "raccoon-185_jpg.rf.bcee2ca430fb3a96dc514b1992e47c0e.jpg\n",
            "raccoon-186_jpg.rf.625d95025f84abf9856080b2faa5c383.jpg\n",
            "raccoon-187_jpg.rf.4f618a6eff7dcd1ec5eaa0c41e00f37f.jpg\n",
            "raccoon-188_jpg.rf.15559b07bc3a0d05391951c53f1955f0.jpg\n",
            "raccoon-189_jpg.rf.43419901d98eee0056c28df38e6513d7.jpg\n",
            "raccoon-18_jpg.rf.37f582b9c3740f41b9b001d6231e9624.jpg\n",
            "raccoon-190_jpg.rf.fe4cbeabd2bb36162b7de124c03ad2f9.jpg\n",
            "raccoon-191_jpg.rf.1d78cbf98a37ddcd43e0d32d68fabf41.jpg\n",
            "raccoon-192_jpg.rf.ca51aeee5c3377d3552b77250546a780.jpg\n",
            "raccoon-193_jpg.rf.03d581ee72066e68248b554e638b6996.jpg\n",
            "raccoon-194_jpg.rf.278aae5524a89af15ef133e713a8fd15.jpg\n",
            "raccoon-195_jpg.rf.51ec933cf17263f4d8b5858eb8206361.jpg\n",
            "raccoon-196_jpg.rf.7675561c8f73dd7dbf67d7d059d9d1c1.jpg\n",
            "raccoon-197_jpg.rf.1618acd413190fefe1ba8db64b8f1611.jpg\n",
            "raccoon-198_jpg.rf.bc433633240733231697f61567a1ba12.jpg\n",
            "raccoon-199_jpg.rf.f94c56b7b4a846f37c5e38e95c1d93c3.jpg\n",
            "raccoon-19_jpg.rf.7267af95f8224c24ae68628b326b9a93.jpg\n",
            "raccoon-1_jpg.rf.86bf2eb4366711ee98b3eff5328302e5.jpg\n",
            "raccoon-200_jpg.rf.d3a7d9a0902b424d082689db76cf99f4.jpg\n",
            "raccoon-20_jpg.rf.244261846b4168eb24f37b25255e2a16.jpg\n",
            "raccoon-21_jpg.rf.3683dd66af9f007fa8340ad62a57bcfd.jpg\n",
            "raccoon-22_jpg.rf.56c95e99e258acd95d54cca330058adf.jpg\n",
            "raccoon-23_jpg.rf.5ab2f34cf8ba061c08a6f247a483fcd3.jpg\n",
            "raccoon-24_jpg.rf.e5da2610dedc18a62487b20f2fdf536f.jpg\n",
            "raccoon-25_jpg.rf.25af8b272e0821ec0c4668826de46b57.jpg\n",
            "raccoon-26_jpg.rf.81e42bb69c8c480289dc656c482e14b0.jpg\n",
            "raccoon-27_jpg.rf.826ff28a701a55c79927c052d879bdbf.jpg\n",
            "raccoon-28_jpg.rf.fe5aedd8ec0f8606941c940bc329eb0e.jpg\n",
            "raccoon-29_jpg.rf.0567862dbebd6fffcaba892ab37b2ddd.jpg\n",
            "raccoon-2_jpg.rf.394e4e2da5f4eb736a6ef2328602d64c.jpg\n",
            "raccoon-30_jpg.rf.d21598f34e1977d0fb06029f6250c6ab.jpg\n",
            "raccoon-31_jpg.rf.b6cbaf67fc83b3abcac857bd719d5249.jpg\n",
            "raccoon-32_jpg.rf.d7b4232bc660c86e4d019040fd1e38c6.jpg\n",
            "raccoon-33_jpg.rf.ae8420e9765b852c7010db558c38f50b.jpg\n",
            "raccoon-34_jpg.rf.726b010640d29591f1ed56d99456a7e5.jpg\n",
            "raccoon-35_jpg.rf.c62e88f203c511ca72c94e3b675b821f.jpg\n",
            "raccoon-36_jpg.rf.d0160b58eabb77c9da48526b1075516a.jpg\n",
            "raccoon-37_jpg.rf.b3ed752a15d92357d867f2fd686979d7.jpg\n",
            "raccoon-38_jpg.rf.5675fe2d015a746eaeece74213190ac9.jpg\n",
            "raccoon-39_jpg.rf.fd9ae13c9c529196f7fb2a291cb14308.jpg\n",
            "raccoon-3_jpg.rf.d69de8d188e9ce4560447c09e2b2895f.jpg\n",
            "raccoon-40_jpg.rf.ff7d6e71001ba529c099bb856103e654.jpg\n",
            "raccoon-41_jpg.rf.e35cfc84d0f7028c4cae77fe88f49ac5.jpg\n",
            "raccoon-42_jpg.rf.6c0893bad5f7066d7ab67e9f6e930148.jpg\n",
            "raccoon-43_jpg.rf.5cb21177b5e0c41d0f1ca42010d82b42.jpg\n",
            "raccoon-44_jpg.rf.cc54a80489215e4d20119067414e7283.jpg\n",
            "raccoon-45_jpg.rf.1480da793fa93f91fe244fc567aed67c.jpg\n",
            "raccoon-46_jpg.rf.e7a366a949d2e6d7fbff5ab4069d03ce.jpg\n",
            "raccoon-47_jpg.rf.672d0251a0441c2e6afd0499aaed4c3a.jpg\n",
            "raccoon-48_jpg.rf.c8630eddd2247c914cd5761cde8768e1.jpg\n",
            "raccoon-49_jpg.rf.fc86a92c2a808a257d529e372f2a123e.jpg\n",
            "raccoon-4_jpg.rf.2f18e7988aed4775867392aa38ccdb35.jpg\n",
            "raccoon-50_jpg.rf.9f6f2e4a156b334f2b88e1254a0b7395.jpg\n",
            "raccoon-51_jpg.rf.8bf83dabfcd0abb0baa44d6647d50629.jpg\n",
            "raccoon-53_jpg.rf.72cbe940898e4f2511fc77ec9a070072.jpg\n",
            "raccoon-54_jpg.rf.d21192d347b1bd3595809549e9066f18.jpg\n",
            "raccoon-55_jpg.rf.cae530a32dfcd3f589fc0d196d4b7c0a.jpg\n",
            "raccoon-56_jpg.rf.fe3e6632931a0ab31a0a303bf0e4b032.jpg\n",
            "raccoon-57_jpg.rf.fefb3f212af9dfeb38411ee2e855ecea.jpg\n",
            "raccoon-58_jpg.rf.4888dd77d2a83089f413f13d95159063.jpg\n",
            "raccoon-59_jpg.rf.6584b902e32ec3936a7fd3997ab72cbc.jpg\n",
            "raccoon-5_jpg.rf.28fdf4e1d910678ae5f41fce0dd03dc7.jpg\n",
            "raccoon-60_jpg.rf.585ecfc2b55fa5b8f4f183d6d077292a.jpg\n",
            "raccoon-61_jpg.rf.c6213e0b4190e43f3d31c75be9e72918.jpg\n",
            "raccoon-62_jpg.rf.3d3012f438c37c1abb71842cd7bb22db.jpg\n",
            "raccoon-63_jpg.rf.40ab9d24c7da1e9e9fb596f478516b61.jpg\n",
            "raccoon-64_jpg.rf.bc00e2ddcc336d5005c9d94335274166.jpg\n",
            "raccoon-66_jpg.rf.55771c3cc5e75cef82e0da3a43f0197a.jpg\n",
            "raccoon-67_jpg.rf.246be1b8226d287a8a7fb35692c1a77d.jpg\n",
            "raccoon-68_jpg.rf.2e710308e7e67745aa4c2518570efb44.jpg\n",
            "raccoon-69_jpg.rf.7409be2f6fcdb4202877b7cee84d0cfd.jpg\n",
            "raccoon-6_jpg.rf.744d0921d61b139fd0d5c0e74ca11740.jpg\n",
            "raccoon-70_jpg.rf.6d4fd75d2f2c02ea0cdee36936024c17.jpg\n",
            "raccoon-71_jpg.rf.240f0810d81630e8ebc3934f9e0c560c.jpg\n",
            "raccoon-72_jpg.rf.09d8c9ddaa3ced1775fcd27de1418ff9.jpg\n",
            "raccoon-73_jpg.rf.8757fde35aa40b69caa4014d0355b272.jpg\n",
            "raccoon-74_jpg.rf.066959b69f0c6562591e814f4341f4cd.jpg\n",
            "raccoon-75_jpg.rf.a516d1392d6c6859b50884b2128d3f21.jpg\n",
            "raccoon-76_jpg.rf.48ea30b685740264da032302faa1bc84.jpg\n",
            "raccoon-77_jpg.rf.8102b983498de2cfc317b57293dc19b9.jpg\n",
            "raccoon-78_jpg.rf.cb2b49d5f1967aa5469a519d8e13ac9f.jpg\n",
            "raccoon-79_jpg.rf.5df522491245bf4a8f3d6fbc12461060.jpg\n",
            "raccoon-7_jpg.rf.dce2f8be9b79db5e6597ffc7ae6f4c86.jpg\n",
            "raccoon-80_jpg.rf.b575161bdf772884fe088c5053279c51.jpg\n",
            "raccoon-81_jpg.rf.3ab8029c18a7e09462a9992bb72c6a26.jpg\n",
            "raccoon-82_jpg.rf.843d438f343388e94dcfe027978edac6.jpg\n",
            "raccoon-83_jpg.rf.0e0db31713d7357475e641139088dac4.jpg\n",
            "raccoon-84_jpg.rf.4a7baffb45287ee96863f030bb0a76b8.jpg\n",
            "raccoon-85_jpg.rf.f1477931a2b7277e01033bee3f7da11b.jpg\n",
            "raccoon-86_jpg.rf.68467edd5d4bd779424dbb9cfc2f08ec.jpg\n",
            "raccoon-87_jpg.rf.f2c7b747fc717134c75aa3e97460ac19.jpg\n",
            "raccoon-88_jpg.rf.d12326b0a21d4195397756fcb2601ea8.jpg\n",
            "raccoon-89_jpg.rf.9d1b4109472683bb28668c160e80a8f4.jpg\n",
            "raccoon-8_jpg.rf.56f046e0ec9164c18dcb786a5d8b56a9.jpg\n",
            "raccoon-90_jpg.rf.352c80a3dfabd3690a8b9c3141025280.jpg\n",
            "raccoon-91_jpg.rf.456ec1187ce1f6cc26efa9efd4812f23.jpg\n",
            "raccoon-92_jpg.rf.133d7820d01e7c6ed215ae7d7e01024a.jpg\n",
            "raccoon-93_jpg.rf.d70f3da0950d00bcd9c9aa23ca56327e.jpg\n",
            "raccoon-94_jpg.rf.c3a646ebb73c5645c2196cad78567fb7.jpg\n",
            "raccoon-95_jpg.rf.3c88c796d81ddbd0a558edb023a29630.jpg\n",
            "raccoon-96_jpg.rf.e979b7f400aeb27038a19702c0dea238.jpg\n",
            "raccoon-97_jpg.rf.0ba0682a10ff3ebc75cf69cc4dead5d6.jpg\n",
            "raccoon-98_jpg.rf.3e84bb66ca7d8c90b24918510a99aba1.jpg\n",
            "raccoon-99_jpg.rf.5e8a99eb16568172b27c208dd0a3a2ef.jpg\n",
            "raccoon-9_jpg.rf.bc05f3ccbc3e5461d54784033ea94f85.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUWFxHW_mjlT"
      },
      "source": [
        "# move everything from the Roboflow export to the root of our keras-yolo3 folder\n",
        "%mv * ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200_8-VImWmK",
        "outputId": "6f6c0cd0-b2d8-47d8-ddd7-93301f1218f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# change directory back to our \n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQASf1hzmxE7",
        "outputId": "9ac88d8f-a875-409d-ae60-6ca2b78c5e78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# show that all our images, _annotations.txt, and _classes.txt made it to our root directory\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_annotations.txt\n",
            "_classes.txt\n",
            "coco_annotation.py\n",
            "convert.py\n",
            "darknet53.cfg\n",
            "\u001b[0m\u001b[01;34mexport\u001b[0m/\n",
            "\u001b[01;34mfont\u001b[0m/\n",
            "kmeans.py\n",
            "LICENSE\n",
            "\u001b[01;34mmodel_data\u001b[0m/\n",
            "raccoon-100_jpg.rf.52f39daea32ee9dc7265a6c591c37313.jpg\n",
            "raccoon-101_jpg.rf.f892f114fd9fa83f9a5a503a0f473a0e.jpg\n",
            "raccoon-102_jpg.rf.45e0bc55ec8c5ed234a7032622fa4343.jpg\n",
            "raccoon-103_jpg.rf.fff35dffbd15d190078b7bba13597813.jpg\n",
            "raccoon-104_jpg.rf.ed0b04834a4c1d3d7e304f429ecca69f.jpg\n",
            "raccoon-105_jpg.rf.635f1284ef2d378438456e10e119f1e2.jpg\n",
            "raccoon-106_jpg.rf.e9025ab979fda072ad42f9b7c8d14657.jpg\n",
            "raccoon-107_jpg.rf.bcebd400f5f02555d1637bac7c1c5f1e.jpg\n",
            "raccoon-108_jpg.rf.deccf8708714c2088ea63055532f816e.jpg\n",
            "raccoon-109_jpg.rf.30bfd64dcc48e0a698628d597a77c538.jpg\n",
            "raccoon-10_jpg.rf.6aafaf3e5397ca2620657903fe4c7eba.jpg\n",
            "raccoon-110_jpg.rf.506fcfbc8dd4175b123fd5064b3471e6.jpg\n",
            "raccoon-111_jpg.rf.f74582eaf6c958c8c96e19d6d557cb45.jpg\n",
            "raccoon-112_jpg.rf.1b6a920ea5e2d9085eea8c70f67aee3f.jpg\n",
            "raccoon-113_jpg.rf.116816776f04bc77daf644271ebbea6e.jpg\n",
            "raccoon-114_jpg.rf.a423d0e91659c2de182a34d59281af27.jpg\n",
            "raccoon-115_jpg.rf.5205b38e218dd901fd21c135975b9fa9.jpg\n",
            "raccoon-117_jpg.rf.84694b89935d96d720922b95709a5e5e.jpg\n",
            "raccoon-118_jpg.rf.79cd0054dbdfe9b2422503a1ca696221.jpg\n",
            "raccoon-119_jpg.rf.9e3522b241e9b90cf5ed6f36d79669ea.jpg\n",
            "raccoon-11_jpg.rf.42a1a7abcfc445e318a674904b043722.jpg\n",
            "raccoon-121_jpg.rf.805b9c0c518bfe5c8926fb0350534228.jpg\n",
            "raccoon-122_jpg.rf.a07845b7b3fe4ca90ac917942f891a08.jpg\n",
            "raccoon-123_jpg.rf.4c33da4a15192e4edbeabeb01c3bc79a.jpg\n",
            "raccoon-124_jpg.rf.5a97e2ade3d1e8bbcf329750a9ccd6ea.jpg\n",
            "raccoon-125_jpg.rf.ed5a8565bfa2f0fdcbc5be2e4b468a2b.jpg\n",
            "raccoon-126_jpg.rf.9fb10a508fd7d2c35b56727d0526c99e.jpg\n",
            "raccoon-127_jpg.rf.812ca10aa7e715abf1149adba9e32597.jpg\n",
            "raccoon-128_jpg.rf.d02d947edecdd0a4281bce7917aa0ab9.jpg\n",
            "raccoon-129_jpg.rf.aa19c70ae1c1c0199a8681c9e9f98753.jpg\n",
            "raccoon-12_jpg.rf.eb97e80628970878966b353cc1cc9aea.jpg\n",
            "raccoon-130_jpg.rf.3b5f11f6dc182d577296f1936de10dd6.jpg\n",
            "raccoon-131_jpg.rf.1847a5d545db92e180fa19e70c8494e3.jpg\n",
            "raccoon-132_jpg.rf.372e4ab6a9f28584576a7f3356e2543f.jpg\n",
            "raccoon-133_jpg.rf.d9bbf773940bf3e55152221c5bf47c25.jpg\n",
            "raccoon-134_jpg.rf.5a43c362ed61b4e6c0f82b6cc29e802e.jpg\n",
            "raccoon-135_jpg.rf.cbba4e3d1c699114824249e5375f47aa.jpg\n",
            "raccoon-136_jpg.rf.e3f0d8942735360a0c7db8fcba8239bc.jpg\n",
            "raccoon-137_jpg.rf.5a2530312b2ba5d5852129a5b9fae725.jpg\n",
            "raccoon-138_jpg.rf.15fb36757722f5a3de5a182eea4ddd1d.jpg\n",
            "raccoon-139_jpg.rf.4974e71827b7315599427fd08f26d4ab.jpg\n",
            "raccoon-13_jpg.rf.7439e7ac8c5d2bf7c06d6d34054d42b7.jpg\n",
            "raccoon-140_jpg.rf.b305669324d984cefd0e302903dfbb61.jpg\n",
            "raccoon-141_jpg.rf.e377c966517aa207bb4c5273fecfbacf.jpg\n",
            "raccoon-142_jpg.rf.ece6d87d78f0061c4707925f753d608a.jpg\n",
            "raccoon-143_jpg.rf.18ff45882e381639888076ae0e396bc2.jpg\n",
            "raccoon-144_jpg.rf.60dba86064a0b8b431d0624b79583115.jpg\n",
            "raccoon-145_jpg.rf.fcc58ad45099f01287b35962d8d075c8.jpg\n",
            "raccoon-146_jpg.rf.923376f3460dcc36a74909d2620e5c1e.jpg\n",
            "raccoon-147_jpg.rf.23be863ec517863aa3e7e26dd652b66f.jpg\n",
            "raccoon-148_jpg.rf.10e85a4558497606e6a129b36207f3e3.jpg\n",
            "raccoon-149_jpg.rf.e46a9a8f9e7260ff48e86815fc0e0dda.jpg\n",
            "raccoon-14_jpg.rf.fc138a4cc4a4cec6a8193a523005b6fd.jpg\n",
            "raccoon-150_jpg.rf.46e71116a4737144dc56f609f7297f14.jpg\n",
            "raccoon-151_jpg.rf.eaf20f212c6d8832667eb12b45b9780e.jpg\n",
            "raccoon-152_jpg.rf.c21589c11e3949ed20f02bc867e491a5.jpg\n",
            "raccoon-153_jpg.rf.416e2ffa4b48443da2cda29beae3a262.jpg\n",
            "raccoon-154_jpg.rf.623df806d7fe78c27f72327370543040.jpg\n",
            "raccoon-155_jpg.rf.a81e6eb3ca44a3896b0c7a984c395872.jpg\n",
            "raccoon-156_jpg.rf.5c67b0af8774e1a803c69dfd57ed3bf9.jpg\n",
            "raccoon-157_jpg.rf.6facfcd86fac6b9ec043e796fbbd1a43.jpg\n",
            "raccoon-158_jpg.rf.f62f5b90800dbcf624fd0a51b789d8aa.jpg\n",
            "raccoon-159_jpg.rf.2c1ee26f22884dcd54cd7cb388027625.jpg\n",
            "raccoon-15_jpg.rf.5bf2e3dc3100e256e042d94a1d88f515.jpg\n",
            "raccoon-160_jpg.rf.14d9cf8c2ee0c1503526e9ee97ef04e6.jpg\n",
            "raccoon-161_jpg.rf.b442cc51e51c950473ec4f7623ce2b07.jpg\n",
            "raccoon-162_jpg.rf.698e8febf42bc8d0e5c144c4989ac7b7.jpg\n",
            "raccoon-163_jpg.rf.7df6926686bffd066db7ffb5777855ee.jpg\n",
            "raccoon-164_jpg.rf.b69dc2b7fb6a02c6d22f658238444dfc.jpg\n",
            "raccoon-165_jpg.rf.51dfb3c8130c8273c2c103834e4889da.jpg\n",
            "raccoon-166_jpg.rf.954cd8bb97ed9638a630b8861e9b17ed.jpg\n",
            "raccoon-167_jpg.rf.951f708822d25cf6526d670611c6f943.jpg\n",
            "raccoon-168_jpg.rf.5699ce9cc71dc0387026d1b16626bf84.jpg\n",
            "raccoon-169_jpg.rf.09a73c6089cf8e4915cc86dab2fd3649.jpg\n",
            "raccoon-16_jpg.rf.58a72de057cdbb407dbcf66244bc5934.jpg\n",
            "raccoon-170_jpg.rf.5d11723aa88f09746fa20bfa0f7d6be9.jpg\n",
            "raccoon-171_jpg.rf.477b2ddd78334618e0c6cdc38d4332eb.jpg\n",
            "raccoon-172_jpg.rf.6001c700d7eb01da8ef7d95f12194dd8.jpg\n",
            "raccoon-173_jpg.rf.1e2fb3444df4c9fd688e8b0ca0366123.jpg\n",
            "raccoon-174_jpg.rf.e311c9dc3467d64ea7553dc3d97741cd.jpg\n",
            "raccoon-175_jpg.rf.b35926e3afc4409406565c0b29e463ee.jpg\n",
            "raccoon-176_jpg.rf.fb8dfc82e718293519ce4f00ed9e3f13.jpg\n",
            "raccoon-177_jpg.rf.e4eb1c989815ce10877db5afa0ebd240.jpg\n",
            "raccoon-178_jpg.rf.2142d32063387bfc178fca79eba27908.jpg\n",
            "raccoon-179_jpg.rf.60de8d933754866816a181e69396559d.jpg\n",
            "raccoon-17_jpg.rf.4a4a70dd81df00203f1903fd6bb009ba.jpg\n",
            "raccoon-180_jpg.rf.386d6a60d32a697211ec1effbf9b0d47.jpg\n",
            "raccoon-181_jpg.rf.268688ca628bb4787fe7a6200b6739cc.jpg\n",
            "raccoon-182_jpg.rf.9a25863af008098d76baf7015cff4bbb.jpg\n",
            "raccoon-183_jpg.rf.4db3a27af872e3171b8c20e7067341b6.jpg\n",
            "raccoon-184_jpg.rf.69dc52b620d9bca66d593079b10622a9.jpg\n",
            "raccoon-185_jpg.rf.bcee2ca430fb3a96dc514b1992e47c0e.jpg\n",
            "raccoon-186_jpg.rf.625d95025f84abf9856080b2faa5c383.jpg\n",
            "raccoon-187_jpg.rf.4f618a6eff7dcd1ec5eaa0c41e00f37f.jpg\n",
            "raccoon-188_jpg.rf.15559b07bc3a0d05391951c53f1955f0.jpg\n",
            "raccoon-189_jpg.rf.43419901d98eee0056c28df38e6513d7.jpg\n",
            "raccoon-18_jpg.rf.37f582b9c3740f41b9b001d6231e9624.jpg\n",
            "raccoon-190_jpg.rf.fe4cbeabd2bb36162b7de124c03ad2f9.jpg\n",
            "raccoon-191_jpg.rf.1d78cbf98a37ddcd43e0d32d68fabf41.jpg\n",
            "raccoon-192_jpg.rf.ca51aeee5c3377d3552b77250546a780.jpg\n",
            "raccoon-193_jpg.rf.03d581ee72066e68248b554e638b6996.jpg\n",
            "raccoon-194_jpg.rf.278aae5524a89af15ef133e713a8fd15.jpg\n",
            "raccoon-195_jpg.rf.51ec933cf17263f4d8b5858eb8206361.jpg\n",
            "raccoon-196_jpg.rf.7675561c8f73dd7dbf67d7d059d9d1c1.jpg\n",
            "raccoon-197_jpg.rf.1618acd413190fefe1ba8db64b8f1611.jpg\n",
            "raccoon-198_jpg.rf.bc433633240733231697f61567a1ba12.jpg\n",
            "raccoon-199_jpg.rf.f94c56b7b4a846f37c5e38e95c1d93c3.jpg\n",
            "raccoon-19_jpg.rf.7267af95f8224c24ae68628b326b9a93.jpg\n",
            "raccoon-1_jpg.rf.86bf2eb4366711ee98b3eff5328302e5.jpg\n",
            "raccoon-200_jpg.rf.d3a7d9a0902b424d082689db76cf99f4.jpg\n",
            "raccoon-20_jpg.rf.244261846b4168eb24f37b25255e2a16.jpg\n",
            "raccoon-21_jpg.rf.3683dd66af9f007fa8340ad62a57bcfd.jpg\n",
            "raccoon-22_jpg.rf.56c95e99e258acd95d54cca330058adf.jpg\n",
            "raccoon-23_jpg.rf.5ab2f34cf8ba061c08a6f247a483fcd3.jpg\n",
            "raccoon-24_jpg.rf.e5da2610dedc18a62487b20f2fdf536f.jpg\n",
            "raccoon-25_jpg.rf.25af8b272e0821ec0c4668826de46b57.jpg\n",
            "raccoon-26_jpg.rf.81e42bb69c8c480289dc656c482e14b0.jpg\n",
            "raccoon-27_jpg.rf.826ff28a701a55c79927c052d879bdbf.jpg\n",
            "raccoon-28_jpg.rf.fe5aedd8ec0f8606941c940bc329eb0e.jpg\n",
            "raccoon-29_jpg.rf.0567862dbebd6fffcaba892ab37b2ddd.jpg\n",
            "raccoon-2_jpg.rf.394e4e2da5f4eb736a6ef2328602d64c.jpg\n",
            "raccoon-30_jpg.rf.d21598f34e1977d0fb06029f6250c6ab.jpg\n",
            "raccoon-31_jpg.rf.b6cbaf67fc83b3abcac857bd719d5249.jpg\n",
            "raccoon-32_jpg.rf.d7b4232bc660c86e4d019040fd1e38c6.jpg\n",
            "raccoon-33_jpg.rf.ae8420e9765b852c7010db558c38f50b.jpg\n",
            "raccoon-34_jpg.rf.726b010640d29591f1ed56d99456a7e5.jpg\n",
            "raccoon-35_jpg.rf.c62e88f203c511ca72c94e3b675b821f.jpg\n",
            "raccoon-36_jpg.rf.d0160b58eabb77c9da48526b1075516a.jpg\n",
            "raccoon-37_jpg.rf.b3ed752a15d92357d867f2fd686979d7.jpg\n",
            "raccoon-38_jpg.rf.5675fe2d015a746eaeece74213190ac9.jpg\n",
            "raccoon-39_jpg.rf.fd9ae13c9c529196f7fb2a291cb14308.jpg\n",
            "raccoon-3_jpg.rf.d69de8d188e9ce4560447c09e2b2895f.jpg\n",
            "raccoon-40_jpg.rf.ff7d6e71001ba529c099bb856103e654.jpg\n",
            "raccoon-41_jpg.rf.e35cfc84d0f7028c4cae77fe88f49ac5.jpg\n",
            "raccoon-42_jpg.rf.6c0893bad5f7066d7ab67e9f6e930148.jpg\n",
            "raccoon-43_jpg.rf.5cb21177b5e0c41d0f1ca42010d82b42.jpg\n",
            "raccoon-44_jpg.rf.cc54a80489215e4d20119067414e7283.jpg\n",
            "raccoon-45_jpg.rf.1480da793fa93f91fe244fc567aed67c.jpg\n",
            "raccoon-46_jpg.rf.e7a366a949d2e6d7fbff5ab4069d03ce.jpg\n",
            "raccoon-47_jpg.rf.672d0251a0441c2e6afd0499aaed4c3a.jpg\n",
            "raccoon-48_jpg.rf.c8630eddd2247c914cd5761cde8768e1.jpg\n",
            "raccoon-49_jpg.rf.fc86a92c2a808a257d529e372f2a123e.jpg\n",
            "raccoon-4_jpg.rf.2f18e7988aed4775867392aa38ccdb35.jpg\n",
            "raccoon-50_jpg.rf.9f6f2e4a156b334f2b88e1254a0b7395.jpg\n",
            "raccoon-51_jpg.rf.8bf83dabfcd0abb0baa44d6647d50629.jpg\n",
            "raccoon-53_jpg.rf.72cbe940898e4f2511fc77ec9a070072.jpg\n",
            "raccoon-54_jpg.rf.d21192d347b1bd3595809549e9066f18.jpg\n",
            "raccoon-55_jpg.rf.cae530a32dfcd3f589fc0d196d4b7c0a.jpg\n",
            "raccoon-56_jpg.rf.fe3e6632931a0ab31a0a303bf0e4b032.jpg\n",
            "raccoon-57_jpg.rf.fefb3f212af9dfeb38411ee2e855ecea.jpg\n",
            "raccoon-58_jpg.rf.4888dd77d2a83089f413f13d95159063.jpg\n",
            "raccoon-59_jpg.rf.6584b902e32ec3936a7fd3997ab72cbc.jpg\n",
            "raccoon-5_jpg.rf.28fdf4e1d910678ae5f41fce0dd03dc7.jpg\n",
            "raccoon-60_jpg.rf.585ecfc2b55fa5b8f4f183d6d077292a.jpg\n",
            "raccoon-61_jpg.rf.c6213e0b4190e43f3d31c75be9e72918.jpg\n",
            "raccoon-62_jpg.rf.3d3012f438c37c1abb71842cd7bb22db.jpg\n",
            "raccoon-63_jpg.rf.40ab9d24c7da1e9e9fb596f478516b61.jpg\n",
            "raccoon-64_jpg.rf.bc00e2ddcc336d5005c9d94335274166.jpg\n",
            "raccoon-66_jpg.rf.55771c3cc5e75cef82e0da3a43f0197a.jpg\n",
            "raccoon-67_jpg.rf.246be1b8226d287a8a7fb35692c1a77d.jpg\n",
            "raccoon-68_jpg.rf.2e710308e7e67745aa4c2518570efb44.jpg\n",
            "raccoon-69_jpg.rf.7409be2f6fcdb4202877b7cee84d0cfd.jpg\n",
            "raccoon-6_jpg.rf.744d0921d61b139fd0d5c0e74ca11740.jpg\n",
            "raccoon-70_jpg.rf.6d4fd75d2f2c02ea0cdee36936024c17.jpg\n",
            "raccoon-71_jpg.rf.240f0810d81630e8ebc3934f9e0c560c.jpg\n",
            "raccoon-72_jpg.rf.09d8c9ddaa3ced1775fcd27de1418ff9.jpg\n",
            "raccoon-73_jpg.rf.8757fde35aa40b69caa4014d0355b272.jpg\n",
            "raccoon-74_jpg.rf.066959b69f0c6562591e814f4341f4cd.jpg\n",
            "raccoon-75_jpg.rf.a516d1392d6c6859b50884b2128d3f21.jpg\n",
            "raccoon-76_jpg.rf.48ea30b685740264da032302faa1bc84.jpg\n",
            "raccoon-77_jpg.rf.8102b983498de2cfc317b57293dc19b9.jpg\n",
            "raccoon-78_jpg.rf.cb2b49d5f1967aa5469a519d8e13ac9f.jpg\n",
            "raccoon-79_jpg.rf.5df522491245bf4a8f3d6fbc12461060.jpg\n",
            "raccoon-7_jpg.rf.dce2f8be9b79db5e6597ffc7ae6f4c86.jpg\n",
            "raccoon-80_jpg.rf.b575161bdf772884fe088c5053279c51.jpg\n",
            "raccoon-81_jpg.rf.3ab8029c18a7e09462a9992bb72c6a26.jpg\n",
            "raccoon-82_jpg.rf.843d438f343388e94dcfe027978edac6.jpg\n",
            "raccoon-83_jpg.rf.0e0db31713d7357475e641139088dac4.jpg\n",
            "raccoon-84_jpg.rf.4a7baffb45287ee96863f030bb0a76b8.jpg\n",
            "raccoon-85_jpg.rf.f1477931a2b7277e01033bee3f7da11b.jpg\n",
            "raccoon-86_jpg.rf.68467edd5d4bd779424dbb9cfc2f08ec.jpg\n",
            "raccoon-87_jpg.rf.f2c7b747fc717134c75aa3e97460ac19.jpg\n",
            "raccoon-88_jpg.rf.d12326b0a21d4195397756fcb2601ea8.jpg\n",
            "raccoon-89_jpg.rf.9d1b4109472683bb28668c160e80a8f4.jpg\n",
            "raccoon-8_jpg.rf.56f046e0ec9164c18dcb786a5d8b56a9.jpg\n",
            "raccoon-90_jpg.rf.352c80a3dfabd3690a8b9c3141025280.jpg\n",
            "raccoon-91_jpg.rf.456ec1187ce1f6cc26efa9efd4812f23.jpg\n",
            "raccoon-92_jpg.rf.133d7820d01e7c6ed215ae7d7e01024a.jpg\n",
            "raccoon-93_jpg.rf.d70f3da0950d00bcd9c9aa23ca56327e.jpg\n",
            "raccoon-94_jpg.rf.c3a646ebb73c5645c2196cad78567fb7.jpg\n",
            "raccoon-95_jpg.rf.3c88c796d81ddbd0a558edb023a29630.jpg\n",
            "raccoon-96_jpg.rf.e979b7f400aeb27038a19702c0dea238.jpg\n",
            "raccoon-97_jpg.rf.0ba0682a10ff3ebc75cf69cc4dead5d6.jpg\n",
            "raccoon-98_jpg.rf.3e84bb66ca7d8c90b24918510a99aba1.jpg\n",
            "raccoon-99_jpg.rf.5e8a99eb16568172b27c208dd0a3a2ef.jpg\n",
            "raccoon-9_jpg.rf.bc05f3ccbc3e5461d54784033ea94f85.jpg\n",
            "README.dataset.txt\n",
            "README.md\n",
            "README.roboflow.txt\n",
            "train_bottleneck.py\n",
            "train.py\n",
            "Tutorial.ipynb\n",
            "voc_annotation.py\n",
            "\u001b[01;34myolo3\u001b[0m/\n",
            "yolo.py\n",
            "yolov3.cfg\n",
            "yolov3-tiny.cfg\n",
            "yolo_video.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvzqgP92W7bt"
      },
      "source": [
        "## Set up and train our model\n",
        "\n",
        "Next, we'll download pre-trained weighs weights from DarkNet, set up our YOLOv3 architecture with those pre-trained weights, and initiate training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJzW08g2VlwD",
        "outputId": "ad469e73-2dbe-4e8b-bbbf-19c80fdb99a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# download our DarkNet weights \n",
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-17 20:07:32--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: yolov3.weights\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   254KB/s    in 12m 13s \n",
            "\n",
            "2020-04-17 20:19:47 (330 KB/s) - yolov3.weights saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mub8GJMBVluA"
      },
      "source": [
        "# call a Python script to set up our architecture with downloaded pre-trained weights\n",
        "!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hBFndz8VeI6",
        "outputId": "7ff87a4a-72e8-4e1f-9d73-fd5daa393676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "Self-contained Python script to train YOLOv3 on your own dataset\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "from yolo3.utils import get_random_data\n",
        "\n",
        "\n",
        "def _main():\n",
        "    annotation_path = '_annotations.txt'  # path to Roboflow data annotations\n",
        "    log_dir = 'logs/000/'                 # where we're storing our logs\n",
        "    classes_path = '_classes.txt'         # path to Roboflow class names\n",
        "    anchors_path = 'model_data/yolo_anchors.txt'\n",
        "    class_names = get_classes(classes_path)\n",
        "    print(\"-------------------CLASS NAMES-------------------\")\n",
        "    print(class_names)\n",
        "    print(\"-------------------CLASS NAMES-------------------\")\n",
        "    num_classes = len(class_names)\n",
        "    anchors = get_anchors(anchors_path)\n",
        "\n",
        "    input_shape = (416,416) # multiple of 32, hw\n",
        "\n",
        "    is_tiny_version = len(anchors)==6 # default setting\n",
        "    if is_tiny_version:\n",
        "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
        "            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
        "    else:\n",
        "        model = create_model(input_shape, anchors, num_classes,\n",
        "            freeze_body=2, weights_path='model_data/yolo.h5') # make sure you know what you freeze\n",
        "\n",
        "    logging = TensorBoard(log_dir=log_dir)\n",
        "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "    val_split = 0.2 # set the size of the validation set\n",
        "    with open(annotation_path) as f:\n",
        "        lines = f.readlines()\n",
        "    np.random.seed(10101)\n",
        "    np.random.shuffle(lines)\n",
        "    np.random.seed(None)\n",
        "    num_val = int(len(lines)*val_split)\n",
        "    num_train = len(lines) - num_val\n",
        "\n",
        "    # Train with frozen layers first, to get a stable loss.\n",
        "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
        "    if True:\n",
        "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
        "            # use custom yolo_loss Lambda layer.\n",
        "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "        batch_size = 32\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "                steps_per_epoch=max(1, num_train//batch_size),\n",
        "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "                validation_steps=max(1, num_val//batch_size),\n",
        "                epochs=100,\n",
        "                initial_epoch=0,\n",
        "                callbacks=[logging, checkpoint])\n",
        "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
        "\n",
        "    #Unfreeze and continue training, to fine-tune.\n",
        "    #Train longer if the result is not good.\n",
        "    if True:\n",
        "        for i in range(len(model.layers)):\n",
        "            model.layers[i].trainable = True\n",
        "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
        "        print('Unfreeze all of the layers.')\n",
        "\n",
        "        batch_size = 8 # note that more GPU memory is required after unfreezing the body\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=100,\n",
        "            initial_epoch=50,\n",
        "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
        "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
        "\n",
        "    #Further training if needed.\n",
        "\n",
        "\n",
        "def get_classes(classes_path):\n",
        "    '''loads the classes'''\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "\n",
        "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/yolo.h5'):\n",
        "    '''create the training model'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "\n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
        "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
        "    '''create the training model, for Tiny YOLOv3'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
        "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
        "\n",
        "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
        "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze the darknet body or freeze all but 2 output layers.\n",
        "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    '''data generator for fit_generator'''\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------CLASS NAMES-------------------\n",
            "['raccoon']\n",
            "-------------------CLASS NAMES-------------------\n",
            "Create YOLOv3 model with 9 anchors and 1 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 18) vs (255, 1024, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((18,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 18) vs (255, 512, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((18,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 18) vs (255, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((18,) vs (255,)).\n",
            "  weight_values[i].shape))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load weights model_data/yolo.h5.\n",
            "Freeze the first 249 layers of total 252 layers.\n",
            "Train on 157 samples, val on 39 samples, with batch size 32.\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 19s 5s/step - loss: 8911.3134 - val_loss: 6531.0596\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 12s 3s/step - loss: 5654.2223 - val_loss: 4107.9380\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 14s 3s/step - loss: 3550.6040 - val_loss: 2590.6719\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 4s 927ms/step - loss: 2269.1837 - val_loss: 1671.8073\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 4s 961ms/step - loss: 1490.3610 - val_loss: 1081.4598\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 4s 962ms/step - loss: 1025.3993 - val_loss: 787.0527\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 735.8914 - val_loss: 554.6812\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 570.6779 - val_loss: 453.1915\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 452.4488 - val_loss: 377.9131\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 376.6848 - val_loss: 303.5693\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 327.8344 - val_loss: 275.3584\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 285.0564 - val_loss: 240.3798\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 258.6553 - val_loss: 227.1732\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 229.7464 - val_loss: 211.0216\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 220.6660 - val_loss: 192.5156\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 202.5139 - val_loss: 190.8709\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 188.7831 - val_loss: 172.6074\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 182.2384 - val_loss: 165.6173\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 170.7375 - val_loss: 150.6042\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 162.9262 - val_loss: 140.2648\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 149.8087 - val_loss: 129.9020\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 146.2981 - val_loss: 131.8061\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 144.4156 - val_loss: 127.3351\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 133.2857 - val_loss: 116.9300\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 10s 2s/step - loss: 126.3661 - val_loss: 118.7722\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 126.7272 - val_loss: 114.7164\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 122.4852 - val_loss: 106.7981\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 10s 2s/step - loss: 114.9615 - val_loss: 97.6676\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 114.4502 - val_loss: 101.9797\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 109.8042 - val_loss: 88.9858\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 107.0234 - val_loss: 94.8470\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 104.0363 - val_loss: 98.1665\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 103.8556 - val_loss: 85.3168\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 10s 2s/step - loss: 101.9166 - val_loss: 84.2840\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 94.0934 - val_loss: 79.7617\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 93.3487 - val_loss: 78.9318\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 10s 2s/step - loss: 86.9855 - val_loss: 82.2324\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 85.9208 - val_loss: 79.0396\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 83.8310 - val_loss: 79.4968\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 85.7409 - val_loss: 75.0917\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 77.9723 - val_loss: 74.6379\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 77.5512 - val_loss: 73.1240\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 76.9540 - val_loss: 73.1669\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 76.4160 - val_loss: 65.7791\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 75.5985 - val_loss: 68.1158\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 73.5888 - val_loss: 66.8525\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 71.2986 - val_loss: 68.3417\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 71.7684 - val_loss: 62.2195\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 70.6725 - val_loss: 56.4572\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 67.5190 - val_loss: 59.9431\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 65.6471 - val_loss: 62.2767\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 63.6065 - val_loss: 61.8450\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 61.7461 - val_loss: 58.4190\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 62.2388 - val_loss: 53.7217\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 60.2120 - val_loss: 55.9796\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 61.5979 - val_loss: 51.9173\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 59.0185 - val_loss: 53.6529\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 57.0400 - val_loss: 52.4717\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 57.7720 - val_loss: 54.6333\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 11s 3s/step - loss: 56.8669 - val_loss: 52.4627\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 54.3403 - val_loss: 49.7256\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 52.5064 - val_loss: 48.5464\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 52.8649 - val_loss: 48.1371\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 52.4749 - val_loss: 49.7113\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 51.6613 - val_loss: 46.4116\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 51.4732 - val_loss: 45.4418\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 50.4974 - val_loss: 47.3276\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 49.7975 - val_loss: 46.1166\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 48.1286 - val_loss: 46.1577\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 48.0473 - val_loss: 45.7724\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 47.6823 - val_loss: 44.3653\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 11s 3s/step - loss: 47.1994 - val_loss: 42.2115\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 45.8731 - val_loss: 42.6242\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 46.3209 - val_loss: 39.5792\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 44.6193 - val_loss: 44.1327\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 45.5648 - val_loss: 41.2319\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 43.9393 - val_loss: 39.6146\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 43.9036 - val_loss: 38.2660\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 10s 2s/step - loss: 45.2046 - val_loss: 38.2178\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 42.1547 - val_loss: 39.5784\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 43.0421 - val_loss: 38.6760\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 41.0531 - val_loss: 37.7720\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 40.8916 - val_loss: 37.6652\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 40.2255 - val_loss: 37.7038\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 40.3435 - val_loss: 36.8555\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 40.5646 - val_loss: 38.3085\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 40.3113 - val_loss: 37.2451\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 39.7364 - val_loss: 36.1330\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 11s 3s/step - loss: 40.2384 - val_loss: 35.6039\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 37.8489 - val_loss: 38.2024\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 11s 3s/step - loss: 39.9102 - val_loss: 33.2546\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 39.2848 - val_loss: 34.9465\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 37.5864 - val_loss: 35.0031\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 37.1514 - val_loss: 35.6939\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 11s 3s/step - loss: 36.1366 - val_loss: 33.7151\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 35.5743 - val_loss: 35.9314\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 36.6111 - val_loss: 33.3778\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 35.9467 - val_loss: 32.8958\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 35.7966 - val_loss: 33.8009\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 10s 3s/step - loss: 36.1847 - val_loss: 33.2067\n",
            "Unfreeze all of the layers.\n",
            "Train on 157 samples, val on 39 samples, with batch size 8.\n",
            "Epoch 51/100\n",
            "19/19 [==============================] - 33s 2s/step - loss: 21.9293 - val_loss: 22.6346\n",
            "Epoch 52/100\n",
            "19/19 [==============================] - 14s 724ms/step - loss: 17.4464 - val_loss: 17.7343\n",
            "Epoch 53/100\n",
            "19/19 [==============================] - 14s 729ms/step - loss: 15.9282 - val_loss: 17.4385\n",
            "Epoch 54/100\n",
            "19/19 [==============================] - 14s 733ms/step - loss: 15.0207 - val_loss: 14.5728\n",
            "Epoch 55/100\n",
            "19/19 [==============================] - 16s 848ms/step - loss: 14.4844 - val_loss: 16.3776\n",
            "Epoch 56/100\n",
            "19/19 [==============================] - 15s 815ms/step - loss: 13.9850 - val_loss: 16.3026\n",
            "Epoch 57/100\n",
            "19/19 [==============================] - 16s 834ms/step - loss: 14.0690 - val_loss: 15.9924\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 58/100\n",
            "19/19 [==============================] - 14s 749ms/step - loss: 13.5995 - val_loss: 15.1853\n",
            "Epoch 59/100\n",
            "19/19 [==============================] - 15s 781ms/step - loss: 13.0948 - val_loss: 14.1691\n",
            "Epoch 60/100\n",
            "19/19 [==============================] - 16s 833ms/step - loss: 13.7257 - val_loss: 15.4064\n",
            "Epoch 61/100\n",
            "19/19 [==============================] - 16s 824ms/step - loss: 13.0473 - val_loss: 15.1401\n",
            "Epoch 62/100\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 13.0941 - val_loss: 14.7803\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 63/100\n",
            "19/19 [==============================] - 16s 832ms/step - loss: 12.9673 - val_loss: 15.6455\n",
            "Epoch 64/100\n",
            "19/19 [==============================] - 16s 834ms/step - loss: 13.1912 - val_loss: 14.0151\n",
            "Epoch 65/100\n",
            "19/19 [==============================] - 16s 819ms/step - loss: 12.8545 - val_loss: 14.0107\n",
            "Epoch 66/100\n",
            "19/19 [==============================] - 16s 830ms/step - loss: 13.1510 - val_loss: 15.0130\n",
            "Epoch 67/100\n",
            "19/19 [==============================] - 16s 829ms/step - loss: 13.1551 - val_loss: 15.0615\n",
            "Epoch 68/100\n",
            "19/19 [==============================] - 16s 835ms/step - loss: 13.0955 - val_loss: 15.4473\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 69/100\n",
            "19/19 [==============================] - 15s 812ms/step - loss: 12.8954 - val_loss: 14.1496\n",
            "Epoch 70/100\n",
            "19/19 [==============================] - 16s 830ms/step - loss: 13.0702 - val_loss: 15.2596\n",
            "Epoch 71/100\n",
            "19/19 [==============================] - 16s 824ms/step - loss: 13.1608 - val_loss: 14.6872\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 72/100\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 12.8458 - val_loss: 14.4299\n",
            "Epoch 73/100\n",
            "19/19 [==============================] - 16s 819ms/step - loss: 13.0339 - val_loss: 14.5016\n",
            "Epoch 74/100\n",
            "19/19 [==============================] - 15s 812ms/step - loss: 13.2875 - val_loss: 14.7160\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 75/100\n",
            "19/19 [==============================] - 16s 831ms/step - loss: 13.0094 - val_loss: 13.0873\n",
            "Epoch 76/100\n",
            "19/19 [==============================] - 16s 823ms/step - loss: 13.1720 - val_loss: 15.0804\n",
            "Epoch 77/100\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 12.8473 - val_loss: 13.6307\n",
            "Epoch 78/100\n",
            "19/19 [==============================] - 16s 834ms/step - loss: 12.9496 - val_loss: 14.8307\n",
            "\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "Epoch 79/100\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 13.0009 - val_loss: 14.7821\n",
            "Epoch 80/100\n",
            "19/19 [==============================] - 16s 825ms/step - loss: 12.9955 - val_loss: 14.0726\n",
            "Epoch 81/100\n",
            "19/19 [==============================] - 16s 824ms/step - loss: 13.1559 - val_loss: 15.2696\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
            "Epoch 82/100\n",
            "19/19 [==============================] - 16s 819ms/step - loss: 13.2592 - val_loss: 14.4566\n",
            "Epoch 83/100\n",
            "19/19 [==============================] - 16s 819ms/step - loss: 13.2335 - val_loss: 15.2009\n",
            "Epoch 84/100\n",
            "19/19 [==============================] - 16s 830ms/step - loss: 12.8563 - val_loss: 14.1757\n",
            "\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
            "Epoch 85/100\n",
            "19/19 [==============================] - 16s 831ms/step - loss: 12.8836 - val_loss: 14.9007\n",
            "Epoch 00085: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48yw4UaOYgQS"
      },
      "source": [
        "## can call this cell instead of the above\n",
        "# !python train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcJbmgNEO1bE",
        "outputId": "a86b0c9a-7f96-44b8-a2e7-76a37c5eced7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Testing on input image\n",
        "!python yolo_video.py --model=\"./logs/000/trained_weights_final.h5\" --classes=\"_classes.txt\" --image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Image detection mode\n",
            " Ignoring remaining command line arguments: ./path2your_video,\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-10-30 05:59:33.023923: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-10-30 05:59:33.024187: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x151ea00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-30 05:59:33.024226: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-30 05:59:33.027053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-30 05:59:33.126053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 05:59:33.126577: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x151ebc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-30 05:59:33.126613: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-30 05:59:33.126793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 05:59:33.127214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-30 05:59:33.127521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-30 05:59:33.128950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-30 05:59:33.130480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-30 05:59:33.130802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-30 05:59:33.132325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-30 05:59:33.133062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-30 05:59:33.135969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-30 05:59:33.136097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 05:59:33.136503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 05:59:33.136847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-30 05:59:33.136904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-30 05:59:33.137710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-30 05:59:33.137739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-30 05:59:33.137752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-30 05:59:33.137867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 05:59:33.138271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 05:59:33.138633: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-30 05:59:33.138681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5864 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "./logs/000/trained_weights_final.h5 model, anchors, and classes loaded.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Input image filename:download.jpg\n",
            "(416, 416, 3)\n",
            "2020-10-30 06:00:32.668840: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-10-30 06:00:32.731320: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] layout failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-10-30 06:00:32.827335: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-10-30 06:00:33.170224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-30 06:00:34.790354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-30 06:00:35.576406: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 2.22G (2387849984 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
            "2020-10-30 06:00:35.576471: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
            "Found 1 boxes for img\n",
            "raccoon 0.50 (32, 0) (341, 416)\n",
            "3.622433782999906\n",
            "Input image filename:"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}